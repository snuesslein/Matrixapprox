{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering collums and rows\n",
    "\n",
    "The idea is to cluster collumns and rows\n",
    "\n",
    "Here we have the objective function \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvsclib.utils as utils\n",
    "import Split\n",
    "import matplotlib.pyplot as plt\n",
    "from tvsclib.strict_system import StrictSystem\n",
    "\n",
    "from tvsclib.approximation import Approximation\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import scipy.stats \n",
    "\n",
    "import graphs\n",
    "\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "import plot_permutations as perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet_target_mats():\n",
    "    target_mats = []\n",
    "    # Load the model\n",
    "    model = models.mobilenet_v2(pretrained=True)\n",
    "    # Put moel into eval mode\n",
    "    model.eval()\n",
    "    for layer in model.classifier:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            # Obtain the weights of this layer\n",
    "            weights = layer.weight.detach().numpy()\n",
    "            target_mats.append(weights)\n",
    "    return target_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.random.rand(32,32)\n",
    "#T = mats = get_mobilenet_target_mats()[0]\n",
    "sys = Split.initial_mixed(T)\n",
    "utils.show_system(sys,mark_D=False)\n",
    "utils.check_dims(sys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute gramians/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get matricies\n",
    "k = 0\n",
    "stage_c=sys.causal_system.stages[k]\n",
    "stage_a=sys.anticausal_system.stages[k]\n",
    "Ac = stage_c.A_matrix\n",
    "Bc = stage_c.B_matrix\n",
    "Cc = stage_c.C_matrix\n",
    "\n",
    "Aa = stage_a.A_matrix\n",
    "Ba = stage_a.B_matrix\n",
    "Ca = stage_a.C_matrix\n",
    "\n",
    "D = stage_c.D_matrix\n",
    "\n",
    "#dims of states\n",
    "\n",
    "(d_out_c,d_in_c) = Ac.shape\n",
    "\n",
    "(d_out_a,d_in_a) = Aa.shape\n",
    "\n",
    "X = np.block([[np.zeros((d_out_a,d_in_c)),Ba,Aa ],\n",
    "              [Cc,D,Ca],\n",
    "              [Ac,Bc,np.zeros((d_out_c,d_in_a))]\n",
    "    \n",
    "])\n",
    "\n",
    "plt.matshow(X)\n",
    "\n",
    "s_c = np.zeros(X.shape[1],dtype=bool)\n",
    "s_c[:d_in_c+D.shape[1]//2]=1\n",
    "s_r = np.zeros(X.shape[0],dtype=bool)\n",
    "s_r[d_out_a+D.shape[0]//2:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l = X[:,s_c]\n",
    "X_r = X[:,~s_c]\n",
    "\n",
    "X_l = X_l/np.linalg.norm(X_l,axis=1).reshape(-1,1)\n",
    "X_r = X_r/np.linalg.norm(X_r,axis=1).reshape(-1,1)\n",
    "\n",
    "X_t = X[~s_r]\n",
    "X_b = X[s_r]\n",
    "\n",
    "X_t = X_t/np.linalg.norm(X_t,axis=0).reshape(1,-1)\n",
    "X_b = X_b/np.linalg.norm(X_b,axis=0).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_b #top or bottom\n",
    "print(np.diag(X_.T@X_))\n",
    "plt.matshow(X_.T@X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_r  #left or right\n",
    "print(np.diag(abs(X_@X_.T)))\n",
    "plt.matshow(X_@X_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(1-abs(X_@X_.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = 1-abs(X_b.T@X_b)\n",
    "np.sum(Adj[:,s_c],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = 1-abs(X_t.T@X_t)\n",
    "np.sum(Adj[:,~s_c],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = 1-abs(X_l@X_l.T)\n",
    "np.sum(Adj[:,s_r],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = 1-abs(X_r@X_r.T)\n",
    "np.sum(Adj[:,~s_r],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,s_col,s_row):\n",
    "    return 0\n",
    "\n",
    "def compute_sigmasf(X,s_col,s_row):\n",
    "    return np.linalg.svd(X[s_row][:,s_col],compute_uv=False), np.linalg.svd(X[~s_row][:,~s_col],compute_uv=False)\n",
    "\n",
    "def show_matrices(X,s_col,s_row):\n",
    "    plt.matshow(X[s_row][:,s_col],fignum=1)\n",
    "\n",
    "    plt.matshow(X[~s_row][:,~s_col],fignum=2)\n",
    "\n",
    "f_reg_row = lambda x: -gamma*x**3\n",
    "f_reg_col = lambda x: -gamma*x**3\n",
    "\n",
    "gamma = 1e4 #maxbee have two different regularizations for rows and collumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_matrix(stage_causal,stage_anticausal,N=70,initla_spectral=True):\n",
    "    \n",
    "    Ac = stage_causal.A_matrix\n",
    "    Bc = stage_causal.B_matrix\n",
    "    Cc = stage_causal.C_matrix\n",
    "\n",
    "    Aa = stage_anticausal.A_matrix\n",
    "    Ba = stage_anticausal.B_matrix\n",
    "    Ca = stage_anticausal.C_matrix\n",
    "\n",
    "    D = stage_causal.D_matrix\n",
    "    \n",
    "    #regularization vector\n",
    "    v_reg_col = f_reg_col(np.linspace(-1,1,D.shape[1]))\n",
    "    v_reg_row = f_reg_row(np.linspace(-1,1,D.shape[0]))\n",
    "\n",
    "    #dims of states\n",
    "    (d_out_c,d_in_c) = Ac.shape\n",
    "    (d_out_a,d_in_a) = Aa.shape\n",
    "\n",
    "    #setup matrix\n",
    "    X = np.block([[np.zeros((d_out_a,d_in_c)),Ba,Aa ],\n",
    "                  [Cc,D,Ca],\n",
    "                  [Ac,Bc,np.zeros((d_out_c,d_in_a))]\n",
    "    \n",
    "    ])\n",
    "\n",
    "    if initla_spectral:\n",
    "        #get initial using spectral \n",
    "        s_c = graphs.segment_matrix(X)\n",
    "        if np.count_nonzero(~s_c[:d_in_c])+np.count_nonzero(s_c[X.shape[1]-d_in_a:]) > (d_in_a+d_in_c)/2:\n",
    "            # if more fixed nodes are incorrect flip\n",
    "            s_c = ~s_c\n",
    "            \n",
    "        #set the fixed\n",
    "        s_c[:d_in_c]=1\n",
    "        s_c[X.shape[1]-d_in_a:]=0\n",
    "        \n",
    "        s_r = graphs.segment_matrix(X.T)\n",
    "        if np.count_nonzero(s_r[:d_out_a])+np.count_nonzero(~s_r[X.shape[0]-d_out_c:]) > (d_out_a+d_out_c)/2:\n",
    "            # if more fixed nodes are incorrect flip\n",
    "            s_r = ~s_r\n",
    "        s_r[:d_out_a]=0\n",
    "        s_r[X.shape[0]-d_out_c:]=1\n",
    "    else:\n",
    "        #initialize segmentation\n",
    "        s_c = np.zeros(X.shape[1],dtype=bool)\n",
    "        s_c[:d_in_c+D.shape[1]//2]=1\n",
    "        s_r = np.zeros(X.shape[0],dtype=bool)\n",
    "        s_r[d_out_a+D.shape[0]//2:]=1\n",
    "    \n",
    "    \n",
    "    fs = np.zeros(N+1)\n",
    "    s_cols=np.zeros((N+1,X.shape[1]),dtype=bool) \n",
    "    s_rows=np.zeros((N+1,X.shape[0]),dtype=bool) \n",
    "    \n",
    "\n",
    "    s_cols[0]=s_c\n",
    "    s_rows[0]=s_r\n",
    "    fs[0]=f(X,s_c,s_r)\n",
    "    \n",
    "    for n in range(N):\n",
    "        #for test \n",
    "        normalize =\"F\"\n",
    "        \n",
    "        #columns:\n",
    "        X_t = X[~s_r]\n",
    "        X_b = X[s_r]\n",
    "        \n",
    "        n_xt =np.linalg.norm(X_t,axis=0)\n",
    "        n_xb =np.linalg.norm(X_b,axis=0)\n",
    "        \n",
    "        #weights unnormalized\n",
    "        W_t = n_xt.reshape(-1,1)*n_xt.reshape(1,-1)-np.abs(X_t.T@X_t)\n",
    "        W_b = n_xb.reshape(-1,1)*n_xb.reshape(1,-1)-np.abs(X_b.T@X_b)\n",
    "        \n",
    "        #nomalize\n",
    "        if normalize ==\"F\": #Forbenius norm\n",
    "            W_t = W_t/(n_xt.reshape(-1,1)*n_xt.reshape(1,-1))\n",
    "            W_b = W_b/(n_xb.reshape(-1,1)*n_xb.reshape(1,-1))\n",
    "        elif normalize ==\"L\": #length\n",
    "            W_t = W_t/(np.count_nonzero(~s_r)**2)\n",
    "            W_b = W_b/(np.count_nonzero(s_r)**2)\n",
    "        elif normalize ==\"M\": #mixed: reference with norm, current with length\n",
    "            W_t = W_t/(n_xt.reshape(-1,1)*np.count_nonzero(~s_r))#\n",
    "            W_b = W_b/(n_xb.reshape(-1,1)*np.count_nonzero(s_r))\n",
    "            \n",
    "        #rows:\n",
    "        X_r = X[:,~s_c]\n",
    "        X_l = X[:,s_c]\n",
    "        \n",
    "        n_xr = np.linalg.norm(X_r,axis=1)\n",
    "        n_xl = np.linalg.norm(X_l,axis=1)\n",
    "        \n",
    "        #Weights unnormalized\n",
    "        W_r =n_xr.reshape(-1,1)*n_xr.reshape(1,-1)-np.abs(X_r@X_r.T)\n",
    "        W_l =n_xl.reshape(-1,1)*n_xl.reshape(1,-1)-np.abs(X_l@X_l.T)\n",
    "        \n",
    "        #normlaize\n",
    "        if normalize ==\"F\": #Forbenius norm\n",
    "            W_r = W_r/(n_xr.reshape(-1,1)*n_xr.reshape(1,-1))\n",
    "            W_l = W_l/(n_xl.reshape(-1,1)*n_xl.reshape(1,-1))\n",
    "        elif normalize ==\"L\": #length\n",
    "            W_r = W_r/(np.count_nonzero(~s_c)**2)#\n",
    "            W_l = W_l/(np.count_nonzero(s_c)**2)\n",
    "        elif normalize ==\"M\": #mixed: reference with norm, current with length\n",
    "            W_r = W_r/(n_xr.reshape(-1,1)*np.count_nonzero(~s_c))#\n",
    "            W_l = W_l/(n_xl.reshape(-1,1)*np.count_nonzero(s_c))\n",
    "\n",
    "        S_col = np.sum(W_t[~s_c],axis=0) -np.sum(W_b[s_c],axis=0)\n",
    "        S_row = np.sum(W_r[~s_r],axis=0) -np.sum(W_l[s_r],axis=0)\n",
    "        \n",
    "        ord_c = d_in_c +np.argsort(S_col[d_in_c:X.shape[1]-d_in_a])\n",
    "        ord_r = d_out_a+np.argsort(S_row[d_out_a:X.shape[0]-d_out_c])\n",
    "        \n",
    "        \n",
    "        v_c = ord_c[v_reg_col<S_col[ord_c]]\n",
    "        v_r = ord_r[v_reg_row<S_row[ord_r]]\n",
    "        \n",
    "        s_c[d_in_c:s_c.size-d_in_a]=0\n",
    "        s_r[d_out_a:s_r.size-d_out_c]=0\n",
    "        \n",
    "        s_c[v_c] = 1\n",
    "        s_r[v_r] = 1\n",
    "        \n",
    "        \n",
    "        fs[n+1] = f(X,s_c,s_r)\n",
    "        s_cols[n+1]=s_c\n",
    "        s_rows[n+1]=s_r\n",
    "        \n",
    "        if np.any(np.logical_and(np.all(s_cols[:n+1]==s_c,axis=1),np.all(s_rows[:n+1]==s_r,axis=1))):\n",
    "            print(\"converged at n=\",n)\n",
    "            break\n",
    "        \n",
    "    report ={\"s_cols\":s_cols[:n+2],\"s_rows\":s_rows[:n+2],\"X\":X}\n",
    "        \n",
    "    return s_c[d_in_c:X.shape[1]-d_in_a],s_r[d_out_a:X.shape[0]-d_out_c],report\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys = Split.initial_mixed(T)\n",
    "stage_c=sys.causal_system.stages[k]\n",
    "stage_a=sys.anticausal_system.stages[k]\n",
    "s_c,s_r,report = segment_matrix(stage_c,stage_a,N=20,initla_spectral=True)\n",
    "s_cols = report[\"s_cols\"]\n",
    "s_rows = report[\"s_rows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_start_c,s_start_a = compute_sigmasf(X,s_cols[0],s_rows[0])\n",
    "s_end_c,s_end_a = compute_sigmasf(X,s_cols[-1],s_rows[-1])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(s_start_c,label=\"start\")\n",
    "plt.plot(s_end_c,label=\"end\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(s_start_a,label=\"start\")\n",
    "plt.plot(s_end_a,label=\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(s_cols)\n",
    "print(np.count_nonzero(s_cols[-1])/len(s_cols[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(s_rows)\n",
    "print(np.count_nonzero(s_cols[-1])/len(s_cols[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helping function to apply permutation and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutations(s_c,s_r):\n",
    "    p_col = np.hstack([np.nonzero(s_c),np.nonzero(~s_c)]).reshape(-1)\n",
    "    p_row = np.hstack([np.nonzero(~s_r),np.nonzero(s_r)]).reshape(-1)\n",
    "    i_in =np.count_nonzero(s_c)\n",
    "    i_out=np.count_nonzero(s_r)\n",
    "    return p_col,p_row,i_in,i_out\n",
    "\n",
    "def permute_stage(stage,p_col,p_row):\n",
    "    stage.B_tilde = stage.B_tilde[:,p_col]\n",
    "    stage.C_tilde = stage.C_tilde[p_row,:]\n",
    "    stage.D_matrix = stage.D_matrix[:,p_col][p_row]\n",
    "    \n",
    "def collect_permutations(P_col,P_row,k,p_col,p_row,system):\n",
    "    \"\"\"\n",
    "    Function to collect the permutations in P_col and P_row\n",
    "    \n",
    "    P_col:    total permutation of columns\n",
    "    P_row:    total permutation of columns\n",
    "    l:        index of stage\n",
    "    p_col:    new collumn permuation\n",
    "    p_row:    new row permutation\n",
    "    \"\"\"\n",
    "    \n",
    "    dims_in = system.dims_in\n",
    "    dims_out = system.dims_out\n",
    "    \n",
    "    I = np.sum(dims_in[:k]).astype(int)\n",
    "    P_col[I:I+dims_in[k]]=P_col[I:I+dims_in[k]][p_col]\n",
    "    I = np.sum(dims_out[:k]).astype(int)\n",
    "    P_row[I:I+dims_out[k]]=P_row[I:I+dims_out[k]][p_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_col=5\n",
    "N_row=4\n",
    "s_c = np.array([0,1]*N_col,dtype=bool)\n",
    "s_r = np.array([0,1]*N_row,dtype=bool)\n",
    "A = np.zeros((1,1))\n",
    "B = np.zeros((1,2*N_col))\n",
    "C = np.zeros((2*N_row,1))\n",
    "D = np.zeros((2*N_row,2*N_col))\n",
    "\n",
    "B[:,s_c]=np.arange(1,N_col+1)\n",
    "B[:,~s_c]=np.arange(N_col+1,2*N_col+1)\n",
    "\n",
    "C[s_r]=np.arange(1,N_row+1).reshape(-1,1)\n",
    "C[s_r]=np.arange(N_row+1,2*N_row+1).reshape(-1,1)\n",
    "\n",
    "index = np.arange(4*N_col*N_row,dtype=int).reshape(2*N_row,2*N_col)\n",
    "D.reshape(-1)[index[s_r][:,s_c].reshape(-1)]=(np.arange(1,N_col+1).reshape(1,-1)*np.arange(1,N_row+1).reshape(-1,1)).reshape(-1)\n",
    "D.reshape(-1)[index[~s_r][:,~s_c].reshape(-1)]=(np.arange(N_col+1,2*N_col+1).reshape(1,-1)*np.arange(N_row+1,2*N_row+1).reshape(-1,1)).reshape(-1)\n",
    "#D[s_r][:,s_c]#D[~s_r][:,~s_c]\n",
    "\n",
    "stage = Split.Stage_sigmas(A,B,C,D,np.ones(1),np.ones(1))\n",
    "p_col,p_row,i_in,i_out = get_permutations(s_c,s_r)\n",
    "permute_stage(stage,p_col,p_row)\n",
    "display(stage.A_matrix)\n",
    "display(stage.B_matrix)\n",
    "display(stage.C_matrix)\n",
    "display(stage.D_matrix)\n",
    "\n",
    "\n",
    "system = StrictSystem(stages=[\n",
    "    Split.Stage_sigmas(np.zeros((1,0)),np.zeros((1,1)),np.zeros((2,0)),np.zeros((2,1)),np.zeros(1),np.zeros(0)),\n",
    "    stage,\n",
    "    Split.Stage_sigmas(np.zeros((0,1)),np.zeros((0,1)),np.zeros((2,1)),np.zeros((2,1)),np.zeros(1),np.zeros(0))\n",
    "],causal=True)\n",
    "utils.show_system(system,mark_D=False)\n",
    "\n",
    "T=linalg.block_diag(np.zeros((2,1)),D,np.zeros((2,1)))\n",
    "P_col = np.arange(T.shape[1],dtype=int)\n",
    "P_row = np.arange(T.shape[0],dtype=int)\n",
    "collect_permutations(P_col,P_row,1,p_col,p_row,system)\n",
    "display(P_col)\n",
    "display(P_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(T[P_row][:,P_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_in =  np.array([4, 4, 4, 4])*6\n",
    "dims_out = np.array([4, 4, 4, 4])*6\n",
    "\n",
    "#dims_in =  np.array([9, 7, 7, 9])*3\n",
    "#dims_out = np.array([7, 9, 9, 7])*3\n",
    "\n",
    "\n",
    "n = 2\n",
    "#create orthogonal vectors and normalize them to the size of the matix (i.e. norm(block)/size(block) = const\n",
    "Us =np.vstack([scipy.stats.ortho_group.rvs(dims_out[i])[:,:3*n]*dims_out[i] for i in range(len(dims_in))])\n",
    "Vts=np.hstack([scipy.stats.ortho_group.rvs(dims_in[i])[:3*n,:]*dims_in[i] for i in range(len(dims_in))])\n",
    "\n",
    "s = np.linspace(1,0.75,n)\n",
    "\n",
    "lower = Us[:,:n]@np.diag(s)@Vts[:n,:]\n",
    "diag = Us[:,n:2*n]@np.diag(s)@Vts[n:2*n,:]\n",
    "upper = Us[:,2*n:3*n]@np.diag(s)@Vts[2*n:3*n,:]\n",
    "matrix = np.zeros_like(diag)\n",
    "a=0;b=0\n",
    "for i in range(len(dims_in)):\n",
    "    matrix[a:a+dims_out[i],:b]            =lower[a:a+dims_out[i],:b]\n",
    "    matrix[a:a+dims_out[i],b:b+dims_in[i]]=diag[a:a+dims_out[i],b:b+dims_in[i]]\n",
    "    matrix[a:a+dims_out[i],b+dims_in[i]:] =upper[a:a+dims_out[i],b+dims_in[i]:]\n",
    "    a+=dims_out[i];b+=dims_in[i]\n",
    "plt.figure()\n",
    "\n",
    "P_in_ref = np.random.permutation(np.arange(matrix.shape[1]))\n",
    "P_out_ref= np.random.permutation(np.arange(matrix.shape[0]))\n",
    "\n",
    "T = matrix[P_out_ref][:,P_in_ref]\n",
    "plt.matshow(T)\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T = np.random.rand(32,32)\n",
    "#T =np.arange(1,32).reshape(1,-1)*np.arange(1,32).reshape(-1,1)\n",
    "#T = matrix.T\n",
    "#T = mats = get_mobilenet_target_mats()[0]\n",
    "sys = Split.initial_sigmas_mixed(T)\n",
    "utils.show_system(sys,mark_D=False)\n",
    "utils.check_dims(sys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine it to algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_split_system(sys,N):\n",
    "    \n",
    "    P_col = np.arange(np.sum(sys.dims_in) ,dtype=int)\n",
    "    P_row = np.arange(np.sum(sys.dims_out),dtype=int)\n",
    "    \n",
    "    Ps_col =np.zeros((N,P_col.size),dtype=int)\n",
    "    Ps_row =np.zeros((N,P_row.size),dtype=int)\n",
    "    for n in range(N):\n",
    "        print(n)\n",
    "        for k in range(len(sys.causal_system.stages)-1,-1,-1): #reverse ordering makes indexing easier \n",
    "            i_in =sys.causal_system.stages[k].dim_in//2\n",
    "            i_out=sys.causal_system.stages[k].dim_out//2\n",
    "            Split.split_sigmas_mixed(sys,k,i_in,i_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys = Split.initial_sigmas_mixed(T)\n",
    "identification_split_system(sys,2)\n",
    "utils.check_dims(sys)\n",
    "utils.show_system(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_causal =[stage.s_in for stage in sys.causal_system.stages][1:]\n",
    "sigmas_anticausal =[stage.s_in for stage in sys.anticausal_system.stages][:-1]\n",
    "#print(sigmas_causal)\n",
    "#print(sigmas_anticausal)\n",
    "plt.subplot(1,2,1)\n",
    "for sig in sigmas_causal:\n",
    "    plt.scatter(np.arange(len(sig)),sig)\n",
    "plt.subplot(1,2,2)\n",
    "for sig in sigmas_anticausal:\n",
    "    plt.scatter(np.arange(len(sig)),sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_split_clustering(sys,N):\n",
    "    \n",
    "    P_col = np.arange(np.sum(sys.dims_in) ,dtype=int)\n",
    "    P_row = np.arange(np.sum(sys.dims_out),dtype=int)\n",
    "    \n",
    "    Ps_col =np.zeros((N+1,P_col.size),dtype=int)\n",
    "    Ps_row =np.zeros((N+1,P_row.size),dtype=int)\n",
    "    Ps_col[0]=P_col\n",
    "    Ps_row[0]=P_row\n",
    "    reports = []\n",
    "    for n in range(N):\n",
    "        print(n)\n",
    "        for k in range(len(sys.causal_system.stages)-1,-1,-1): #reverse ordering makes indexing easier \n",
    "            stage_c=sys.causal_system.stages[k]\n",
    "            stage_a=sys.anticausal_system.stages[k]\n",
    "            s_c,s_r,report = segment_matrix(stage_c,stage_a,N=20)\n",
    "            reports.append(report)\n",
    "            \n",
    "            assert len(s_c)==stage_c.dim_in ,\"dims_in causal do not match s_c\"\n",
    "            assert len(s_r)==stage_c.dim_out,\"dims_out causal do not match s_r\"\n",
    "            assert len(s_c)==stage_a.dim_in ,\"dims_in antic do not match s_c\"\n",
    "            assert len(s_r)==stage_a.dim_out,\"dims_out antic do not match s_r\"\n",
    "            p_col,p_row,i_in,i_out = get_permutations(s_c,s_r)\n",
    "            permute_stage(stage_c,p_col,p_row)\n",
    "            permute_stage(stage_a,p_col,p_row)\n",
    "            collect_permutations(P_col,P_row,k,p_col,p_row,sys)\n",
    "            \n",
    "            Split.split_sigmas_mixed(sys,k,i_in,i_out)\n",
    "        #save the Permutations collected for all stages\n",
    "        Ps_col[n+1]=P_col\n",
    "        Ps_row[n+1]=P_row\n",
    "    \n",
    "    return Ps_col,Ps_row,reports"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Transpose to check for assymetries in algorithm\n",
    "T = T.T\n",
    "P_in_ref,P_out_ref = (P_out_ref,P_in_ref )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1e6\n",
    "sys = Split.initial_sigmas_mixed(T)\n",
    "Ps_col,Ps_row,reports = identification_split_clustering(sys,2)\n",
    "P_col = Ps_col[-1]\n",
    "P_row = Ps_row[-1]\n",
    "utils.check_dims(sys)\n",
    "utils.show_system(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.scatter(np.arange(len(P_col)),P_col)\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(np.arange(len(P_row)),P_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_causal =[stage.s_in for stage in sys.causal_system.stages][1:]\n",
    "sigmas_anticausal =[stage.s_in for stage in sys.anticausal_system.stages][:-1]\n",
    "#print(sigmas_causal)\n",
    "#print(sigmas_anticausal)\n",
    "plt.subplot(1,2,1)\n",
    "for i,sig in enumerate(sigmas_causal):\n",
    "    plt.scatter(np.arange(len(sig)),sig,label=str(i))\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "for i,sig in enumerate(sigmas_anticausal):\n",
    "    plt.scatter(np.arange(len(sig)),sig,label=str(i))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(T[P_row][:,P_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(T[Ps_row[-1]][:,Ps_col[-1]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.matshow(T[P_row][:,P_col]-sys.to_matrix())\n",
    "np.max(np.abs(T[P_row][:,P_col]-sys.to_matrix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_dims(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('tab20')\n",
    "colors = np.repeat(cmap((1/20)*np.arange(4)+0.001),dims_in,axis=0)[P_in_ref]\n",
    "perm.multiple_connection_plot(perm.invert_permutations(Ps_col),colors=colors,start=0,end=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('tab20')\n",
    "colors = np.repeat(cmap((1/20)*np.arange(4)+0.001),dims_out,axis=0)[P_out_ref]\n",
    "perm.multiple_connection_plot(perm.invert_permutations(Ps_row),colors=colors,start=0,end=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.matshow(reports[0][\"X\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight matrix form Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = get_mobilenet_target_mats()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys = Split.initial_sigmas_mixed(T)\n",
    "identification_split_system(sys,3)\n",
    "utils.check_dims(sys)\n",
    "utils.show_system(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_causal =[stage.s_in for stage in sys.causal_system.stages][1:]\n",
    "sigmas_anticausal =[stage.s_in for stage in sys.anticausal_system.stages][:-1]\n",
    "#print(sigmas_causal)\n",
    "#print(sigmas_anticausal)\n",
    "plt.subplot(1,2,1)\n",
    "for sig in sigmas_causal:\n",
    "    plt.scatter(np.arange(len(sig)),sig)\n",
    "plt.subplot(1,2,2)\n",
    "for sig in sigmas_anticausal:\n",
    "    plt.scatter(np.arange(len(sig)),sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 5e3\n",
    "\n",
    "sys_per = Split.initial_sigmas_mixed(T)\n",
    "Ps_col,Ps_row,reporst = identification_split_clustering(sys_per,3)\n",
    "utils.check_dims(sys_per)\n",
    "utils.show_system(sys_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_causal =[stage.s_in for stage in sys_per.causal_system.stages][1:]\n",
    "sigmas_anticausal =[stage.s_in for stage in sys_per.anticausal_system.stages][:-1]\n",
    "#print(sigmas_causal)\n",
    "#print(sigmas_anticausal)\n",
    "plt.subplot(1,2,1)\n",
    "for sig in sigmas_causal:\n",
    "    plt.scatter(np.arange(len(sig)),sig)\n",
    "plt.subplot(1,2,2)\n",
    "for sig in sigmas_anticausal:\n",
    "    plt.scatter(np.arange(len(sig)),sig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perm.multiple_connection_plot(perm.invert_permutations(Ps_col),start=0,end=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perm.multiple_connection_plot(perm.invert_permutations(Ps_row),start=0,end=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigmas_causal_per =[stage.s_in for stage in sys_per.causal_system.stages][1:]\n",
    "sigmas_anticausal_per =[stage.s_in for stage in sys_per.anticausal_system.stages][:-1]\n",
    "\n",
    "sigmas_causal =[stage.s_in for stage in sys.causal_system.stages][1:]\n",
    "sigmas_anticausal =[stage.s_in for stage in sys.anticausal_system.stages][:-1]\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.grid()\n",
    "for sig in sigmas_causal:\n",
    "    plt.plot(np.arange(len(sig)),sig,color='C0')\n",
    "for sig in sigmas_causal_per:\n",
    "    plt.plot(np.arange(len(sig)),sig,color='C1')\n",
    "plt.subplot(1,2,2)\n",
    "for sig in sigmas_anticausal:\n",
    "    plt.plot(np.arange(len(sig)),sig,color='C0')\n",
    "for sig in sigmas_anticausal_per:\n",
    "    plt.plot(np.arange(len(sig)),sig,color='C1')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_per = T[Ps_row[-1]][:,Ps_col[-1]]\n",
    "np.max(np.abs(T_per-sys_per.to_matrix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_max = max([np.max(sig)for sig in sigmas_causal]+[np.max(sig)for sig in sigmas_anticausal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx =Approximation(sys,(sigmas_causal,sigmas_anticausal))\n",
    "approx_per=Approximation(sys_per,(sigmas_causal_per,sigmas_anticausal_per))\n",
    "\n",
    "\n",
    "N = 9 #number of points\n",
    "alpha = np.linspace(0,1,N)\n",
    "\n",
    "err_move =np.zeros_like(alpha)\n",
    "\n",
    "eps = eps_max*alpha\n",
    "\n",
    "def calc_values(approx,eps,matrix):\n",
    "    costs =np.zeros_like(eps)\n",
    "    err =np.zeros_like(eps)\n",
    "    for i in range(len(eps)):\n",
    "        approx_system=approx.get_approxiamtion(eps[i])\n",
    "        matrix_approx = approx_system.to_matrix()\n",
    "        err[i] = np.linalg.norm(matrix_approx-matrix,ord=2)\n",
    "        costs[i] = approx_system.cost()\n",
    "    return err,costs\n",
    "\n",
    "err_orig,cost_orig = calc_values(approx,eps,T)\n",
    "err_per,cost_per = calc_values(approx_per,eps,T_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_orig,err_orig,label=\"orig\")\n",
    "plt.plot(cost_per,err_per,label=\"per\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_orig[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_per[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_orig[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_per[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(alpha[i])\n",
    "print(1-cost_per[i]/cost_orig[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(err_per[i]/err_orig[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alpha,cost_per/cost_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
